<?xml version="1.0" encoding="UTF-8"?>

<configuration status="debug" monitorInterval="10">
    <!--先定义所有的appender-->
    <appenders>
        <!--这个输出控制台的配置-->
        <Console name="Console" target="SYSTEM_OUT">
            <!--控制台只输出level及以上级别的信息（onMatch），其他的直接拒绝（onMismatch）-->
            <ThresholdFilter level="trace" onMatch="ACCEPT" onMismatch="DENY"/>
            <!--这个都知道是输出日志的格式-->
            <PatternLayout pattern="[%d{yyyy-MM-dd HH:mm:ss z}] [logId:%X{logId}] [%X{RealClass}] [%-5level] %msg%xEx%n"/>
        </Console>

        <!--这个会打印出所有的信息，每次大小超过size，则这size大小的日志会自动存入按年份-月份建立的文件夹下面并进行压缩，作为存档-->
        <RollingFile name="RollingFile" fileName="logs/app.log"
                     filePattern="logs/$${date:yyyy-MM}/app-%d{MM-dd-yyyy}-%i.log.gz">
            <PatternLayout pattern="[%d{yyyy-MM-dd HH:mm:ss z}] [logId:%X{logId}] [%X{RealClass}] [%-5level] %msg%xEx%n"/>
            <Policies>
                <!--<TimeBasedTriggeringPolicy interval="1" modulate="true" />-->
                <SizeBasedTriggeringPolicy size="1024MB"/>
            </Policies>
            <DefaultRolloverStrategy max="100"/>
        </RollingFile>

        <errorHandler class="org.apache.logging.log4j.core.ErrorHandler">
            <root-ref/>
            <appender-ref ref="Console"/>
        </errorHandler>
        <!-- 输出错误日志到Kafka -->
        <Kafka name="KAFKA" topic="financial-web">
            <ThresholdFilter level="debug" onMatch="ACCEPT" onMismatch="DENY" />
            <PatternLayout pattern="[%d{yyyy-MM-dd HH:mm:ss z}] [logId:%X{logId}] [%X{RealClass}] [%-5level] %msg%xEx%n"/>
            <!--<JsonLayout/>-->
            <Property name="bootstrap.servers">10.1.210.50:9092</Property>
            <Property name="acks">0</Property>
            <Property name="compression.type">gzip</Property>
            <Property name="batch.size">16384</Property>
            <Property name="linger.ms">10</Property>
            <Property name="timeout.ms">10</Property>
            <Property name="metadata.fetch.timeout.ms">10</Property>
            <Property name="max.block.ms">5</Property>
            <Property name="retries">0</Property>
        </Kafka>
    </appenders>
    <!--然后定义logger，只有定义了logger并引入的appender，appender才会生效-->
    <loggers>
        <!--建立一个默认的root的logger-->
        <Root level="debug">
            <appender-ref ref="RollingFile"/>
            <appender-ref ref="Console"/>
            <appender-ref ref="KAFKA"/>
        </Root>

        <AsyncLogger name="org.apache.kafka" level="ERROR" additivity="false">
            <AppenderRef ref="Console" />
            <AppenderRef ref="RollingFile" />
        </AsyncLogger>

        <AsyncLogger name="com.ucl.dao" level="DEBUG" additivity="false">
            <AppenderRef ref="Console" />
            <AppenderRef ref="RollingFile" />
            <appender-ref ref="KAFKA"/>
        </AsyncLogger>
        <AsyncLogger name="net.sf.log4jdbc" level="ERROR" additivity="true">
            <AppenderRef ref="Console" />
            <AppenderRef ref="RollingFile" />
        </AsyncLogger>

        <AsyncLogger name="com.ucl.dao" level="ERROR" additivity="true">
            <AppenderRef ref="Console" />
            <AppenderRef ref="RollingFile" />
            <appender-ref ref="KAFKA"/>
        </AsyncLogger>
    </loggers>
</configuration>